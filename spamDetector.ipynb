{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e9601c",
   "metadata": {},
   "source": [
    "<h1> Title: Spam Detection</h1>\n",
    "\n",
    "<strong>Overview: In this notebook, I aim to detect spam comments</strong><br>\n",
    "In this notebook, it covers:<br>\n",
    "1.0 Heuristic Labeling<br>\n",
    "2.0 Zero-Shot using API<br>\n",
    "3.0 Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7133ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ed0e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     The, uh, *shape* of the containers is somethin...\n",
       "1           And with perfect people like you √¢¬ù¬§√Ø¬∏¬è√∞≈∏≈í¬∏\n",
       "2     Please don't call me sirüòÖüòÖ best part is you re...\n",
       "3     Lol All you need is to put your hair in two po...\n",
       "4                         It's \"for the record\" by Ooyy\n",
       "                            ...                        \n",
       "95                                                   ??\n",
       "96    Omg this is the cutest ever well done and I mi...\n",
       "97    i didn't like the dry down of carlisle, i have...\n",
       "98        KJo should cast him opposition Ranveer Singh.\n",
       "99    Always at work when you post ü§¶üèæ‚Äç‚ôÄÔ∏è going to ha...\n",
       "Name: textOriginal, Length: 100, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/comments.csv',nrows=100)\n",
    "df[\"textOriginal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf153c",
   "metadata": {},
   "source": [
    "## 1.0 Heuristic Labeling (Rule-based Bootstrapping)\n",
    "- Create a set of rules to automatically label\n",
    "\n",
    "Strengths: \n",
    "- Fast to implement.\n",
    "- Can capture obvious spam patterns (URLs, ‚Äúfollow me,‚Äù mass tagging).\n",
    "\n",
    "Weaknesses:\n",
    "- Misses subtle spam \n",
    "- May mislabel genuine comments with links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13d82c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_label(comment: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the comment is considered spam based on heuristic rules,\n",
    "    otherwise False.\n",
    "    \"\"\"\n",
    "    # Normalize text\n",
    "    text = comment.lower().strip()\n",
    "    \n",
    "    # Rule 1: Suspicious keywords / links \n",
    "    spam_keywords = [\n",
    "        \"http://\", \"https://\", \"www.\",\n",
    "        \"check out my\", \"follow me\",\n",
    "        \"@@\", \"free\", \"subscribe\", \"visit my\",\n",
    "        \"win money\", \"free gift\", \"dm for promo\", \"subscribe my channel\"\n",
    "    ]\n",
    "    if any(keyword in text for keyword in spam_keywords):\n",
    "        return True\n",
    "    \n",
    "    # Rule 2: Regex patterns\n",
    "    regex_patterns = [\n",
    "        r\"[a-z0-9]{20,}\",   # Long alphanumeric strings (promo codes etc.)\n",
    "        r\"([!@#$%^&*()_+=\\-{}\\[\\]:;\\\"'<>,.?/\\\\|]){5,}\",  # Excessive special chars\n",
    "        r\"http[s]?://\"      # URLs\n",
    "    ]\n",
    "    for pattern in regex_patterns:\n",
    "        if re.search(pattern, text):\n",
    "            return True\n",
    "    \n",
    "    # Rule 3: Very short (1‚Äì3 words) generic comments\n",
    "    if len(text.split()) <= 2:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "153ab29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6                                               Alright\n",
      "16                             √∞≈∏Àú¬Æ√∞≈∏Àú¬Æ√∞≈∏Àú¬Æ√∞≈∏Àú¬Æ√∞≈∏Àú¬Æ√∞≈∏Àú¬Æ\n",
      "19                                                ‚ù§‚ù§‚ù§‚ù§‚ù§\n",
      "20                                                 ‚ù§‚ù§‚ù§‚ù§\n",
      "23                                                 Bhhh\n",
      "25                                    √¢¬ù¬§√∞≈∏Àú‚Äö√¢¬ù¬§√∞≈∏Àú‚Äö√¢¬ù¬§\n",
      "27                                                   üí•üí•\n",
      "28                                              TrueüòÇüòÇ‚ù§\n",
      "30                                              Nice√¢¬ù¬§\n",
      "31                                     Elegant makeover\n",
      "37                                                  √¢¬ù¬§\n",
      "40                                                  ‚ù§‚ù§‚ù§\n",
      "45                                          ReuploadedüòÇ\n",
      "51                                       Superb content\n",
      "53                                              Hii sis\n",
      "55                          üëçüèΩüëçüèΩüëçüèΩüëçüèΩ‚ù§Ô∏èüíôüíõüíõüß°so coolüëçüèΩüëçüèΩüëçüèΩ\n",
      "56                                           Thankiiies\n",
      "59                                         √∞≈∏Àú‚Äö√∞≈∏Àú‚Äö√∞≈∏‚Äò¬ç\n",
      "62                                               Good ‚ù§\n",
      "65                                        Let‚Äôs connect\n",
      "66                                              Awesome\n",
      "67                                           Trop belle\n",
      "70                                               √¢¬ù¬§√¢¬ù¬§\n",
      "73    @@SunitaRawat-tz4nbwhen i went to go look on t...\n",
      "75                                             Will do!\n",
      "78                                                 Call\n",
      "80                                 Absolutely essential\n",
      "83                                           √∞≈∏‚Ñ¢‚Äπ√¢≈ì≈í√Ø¬∏¬è\n",
      "85                                        Which shade??\n",
      "86                                            Beautiful\n",
      "90                             √∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏‚Äô‚Äπ\n",
      "94                                                 üå∏üå∏üå∏üå∏\n",
      "95                                                   ??\n",
      "Name: textOriginal, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply heuristic labeling\n",
    "df[\"spam\"] = df[\"textOriginal\"].apply(heuristic_label)\n",
    "\n",
    "# Print only spam comments\n",
    "spam_comments = df[df[\"spam\"] == True]\n",
    "print(spam_comments[\"textOriginal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166686c",
   "metadata": {},
   "source": [
    "## 2.0 Zero-Shot with LLM API (Pseudo-labeling)\n",
    "- Use a large language model (LLM) API or a to generate \"pseudo-labels\"\n",
    "\n",
    "Strengths:\n",
    "- Can handle nuanced cases heuristics miss.\n",
    "- No need to manually annotate everything.\n",
    "\n",
    "Weaknesses:\n",
    "- Expensive at scale.\n",
    "- Quality depends on prompt + LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=\"\") # set your API key as environment variable: OPENAI_API_KEY / OPENROUTER_API_KEY\n",
    "\n",
    "def zero_shot(comment: str) -> str:\n",
    "    \"\"\"\n",
    "    Use an LLM to pseudo-label a comment as 'spam' or 'not spam'.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a spam detection system.\n",
    "    Classify the following comment as either 'spam' or 'not spam'.\n",
    "    Only output 'spam' or 'not spam'.\n",
    "\n",
    "    Comment: \"{comment}\"\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  # /\"gpt-4o-mini\"\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    label = response.choices[0].message.content.strip().lower()\n",
    "    return label if label in [\"spam\", \"not spam\"] else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d2c986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         textOriginal  spam\n",
      "10                       Share it. Share it. Share it  spam\n",
      "72  hey bro..your really handsome lovely..would li...  spam\n",
      "83                                         √∞≈∏‚Ñ¢‚Äπ√¢≈ì≈í√Ø¬∏¬è  spam\n",
      "90                           √∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏‚Äô‚Äπ  spam\n"
     ]
    }
   ],
   "source": [
    "# Apply Zero shot\n",
    "df[\"spam\"] = df[\"textOriginal\"].apply(zero_shot)\n",
    "\n",
    "# Filter only spam\n",
    "spam_comments = df[df[\"spam\"] == \"spam\"]\n",
    "\n",
    "print(spam_comments[[\"textOriginal\", \"spam\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513dd85a",
   "metadata": {},
   "source": [
    "## 3.0 Pre-trained Spam Detection Model\n",
    "\n",
    "Strengths:\n",
    "- Already optimized for spam/ham classification.\n",
    "- Usually faster & cheaper than LLM APIs.\n",
    "\n",
    "Weaknesses:\n",
    "- May not generalize perfectly to video comment domain (different slang, formats)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2061c6",
   "metadata": {},
   "source": [
    "<h3>Label Description</h3>\n",
    "\n",
    "1. **Noise**: Gibberish at the zero level where even the different constituents of the input phrase (words) do not hold any meaning independently.\n",
    "    - For example: dfdfer fgerfow2e0d qsqskdsd djksdnfkff swq.\n",
    "\n",
    "2. **Word Salad**: Gibberish at level 1 where words make sense independently, but when looked at the bigger picture (the phrase) any meaning is not depicted.\n",
    "    - For example: 22 madhur old punjab pickle chennai\n",
    "\n",
    "3. **Mild gibberish**: Gibberish at level 2 where there is a part of the sentence that has grammatical errors, word sense errors, or any syntactical abnormalities, which leads the sentence to miss out on a coherent meaning.\n",
    "    - For example: Madhur study in a teacher\n",
    "\n",
    "4. **Clean**: This category represents a set of words that form a complete and meaningful sentence on its own.\n",
    "    - For example: I love this website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de90a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         textOriginal            spam\n",
      "0   The, uh, *shape* of the containers is somethin...  mild gibberish\n",
      "1         And with perfect people like you √¢¬ù¬§√Ø¬∏¬è√∞≈∏≈í¬∏      word salad\n",
      "2   Please don't call me sirüòÖüòÖ best part is you re...  mild gibberish\n",
      "3   Lol All you need is to put your hair in two po...           clean\n",
      "4                       It's \"for the record\" by Ooyy           clean\n",
      "..                                                ...             ...\n",
      "95                                                 ??      word salad\n",
      "96  Omg this is the cutest ever well done and I mi...  mild gibberish\n",
      "97  i didn't like the dry down of carlisle, i have...  mild gibberish\n",
      "98      KJo should cast him opposition Ranveer Singh.  mild gibberish\n",
      "99  Always at work when you post ü§¶üèæ‚Äç‚ôÄÔ∏è going to ha...  mild gibberish\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer from Hugging Face Hub\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"madhurjindal/autonlp-Gibberish-Detector-492513457\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"madhurjindal/autonlp-Gibberish-Detector-492513457\")\n",
    "\n",
    "# Predicts whether a list of comments is spam using a pre-trained model.\n",
    "def pretrained_model(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predicted_label_id = probabilities.argmax().item()\n",
    "    \n",
    "    return model.config.id2label[predicted_label_id]\n",
    "\n",
    "df[\"spam\"] = df[\"textOriginal\"].apply(pretrained_model)\n",
    "\n",
    "print(df[[\"textOriginal\", \"spam\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbe23716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "mild gibberish    46\n",
      "clean             25\n",
      "noise             17\n",
      "word salad        12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"spam\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8947cb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         textOriginal   spam\n",
      "3   Lol All you need is to put your hair in two po...  clean\n",
      "4                       It's \"for the record\" by Ooyy  clean\n",
      "7      Please show us what these are like in the sun.  clean\n",
      "8                   This is a great point, thank you!  clean\n",
      "9   Pretty brave to try it anyway after dreaming t...  clean\n",
      "10                       Share it. Share it. Share it  clean\n",
      "17  Everything looks great except the red hat on b...  clean\n",
      "18  Can you comb or brush through it without it co...  clean\n",
      "24  Is there a semi permanent hair dye out there t...  clean\n",
      "29       Does anyone know the title of the intro song  clean\n",
      "31                                   Elegant makeover  clean\n",
      "36           I'm so glad it worked. It looks so cool.  clean\n",
      "38  I thought she was taking a screenshot in the w...  clean\n",
      "47  You could but some of the product would defini...  clean\n",
      "49  Would totally depend on the style of the outfi...  clean\n",
      "50  You're so pretty Aislinn! üíñ glad this didn't f...  clean\n",
      "58  I feel like it'd be so cool for someone to dye...  clean\n",
      "65                                      Let‚Äôs connect  clean\n",
      "72  hey bro..your really handsome lovely..would li...  clean\n",
      "76  This product would be great for kids. My 2 gir...  clean\n",
      "79  Hi Aislinn! Would you be willing to try this o...  clean\n",
      "80                               Absolutely essential  clean\n",
      "81  I've been curious about these. Thanks for show...  clean\n",
      "84                  I agree that you are beautiful <3  clean\n",
      "89  Interested to know your thoughts on Akaster? N...  clean\n"
     ]
    }
   ],
   "source": [
    "# Filter only rows predicted as clean\n",
    "clean_df = df[df[\"spam\"] == \"clean\"]\n",
    "\n",
    "print(clean_df[[\"textOriginal\", \"spam\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "852b7715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         textOriginal   spam\n",
      "12  I'm so happy thanks for the song √¢¬ù¬§√¢¬ù¬§√¢¬ù¬§√¢¬ù¬§√∞...  noise\n",
      "13                                Muito preciosa √∞≈∏‚Äô≈Ω  noise\n",
      "14  Como carajo usas una gorra pobre fracasado? Ja...  noise\n",
      "21               Bhaii lacto calamine pe video bna do  noise\n",
      "23                                               Bhhh  noise\n",
      "25                                  √¢¬ù¬§√∞≈∏Àú‚Äö√¢¬ù¬§√∞≈∏Àú‚Äö√¢¬ù¬§  noise\n",
      "32                           Love from India √∞≈∏‚Ä°¬Æ√∞≈∏‚Ä°¬≥  noise\n",
      "33   iw ye hee hee cade i‚ù§dvv birweüòÇgüéâisod I love you  noise\n",
      "34  Baal to mere bhi jhad rahe hai...\\n.\\n.\\nPar m...  noise\n",
      "53                                            Hii sis  noise\n",
      "59                                       √∞≈∏Àú‚Äö√∞≈∏Àú‚Äö√∞≈∏‚Äò¬ç  noise\n",
      "69                             Handsome √¢¬ù≈Ω chapri√¢≈ì‚Ä¶  noise\n",
      "70                                             √¢¬ù¬§√¢¬ù¬§  noise\n",
      "71  C'est une blague tous ces avis n√©gatifs ? C'es...  noise\n",
      "83                                         √∞≈∏‚Ñ¢‚Äπ√¢≈ì≈í√Ø¬∏¬è  noise\n",
      "90                           √∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏¬•¬∞√∞≈∏‚Äô‚Äπ  noise\n",
      "92  wow nice bhe ganda ng outfit mo like ko ung sh...  noise\n"
     ]
    }
   ],
   "source": [
    "# Filter only rows predicted as noise\n",
    "noise_df = df[df[\"spam\"] == \"noise\"]\n",
    "\n",
    "print(noise_df[[\"textOriginal\", \"spam\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "935df423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         textOriginal        spam\n",
      "1         And with perfect people like you √¢¬ù¬§√Ø¬∏¬è√∞≈∏≈í¬∏  word salad\n",
      "61                                   Her smile tho ‚ù§ü§ó  word salad\n",
      "62                                             Good ‚ù§  word salad\n",
      "64                            How old are you sir √¢¬ù¬§  word salad\n",
      "66                                            Awesome  word salad\n",
      "73  @@SunitaRawat-tz4nbwhen i went to go look on t...  word salad\n",
      "74                                    Coming soon. :)  word salad\n",
      "75                                           Will do!  word salad\n",
      "82                         This blonde hair though!!‚ù§  word salad\n",
      "86                                          Beautiful  word salad\n",
      "88                              Nope. English upload.  word salad\n",
      "95                                                 ??  word salad\n"
     ]
    }
   ],
   "source": [
    "# Filter only rows predicted as word salad\n",
    "salad_df = df[df[\"spam\"] == \"word salad\"]\n",
    "\n",
    "print(salad_df[[\"textOriginal\", \"spam\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72772bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         textOriginal            spam\n",
      "0   The, uh, *shape* of the containers is somethin...  mild gibberish\n",
      "2   Please don't call me sirüòÖüòÖ best part is you re...  mild gibberish\n",
      "5     All that to look just above average teanage boy  mild gibberish\n",
      "6                                             Alright  mild gibberish\n",
      "11   What lash searums do you recommend that is cheap  mild gibberish\n",
      "15                                 Plz toner recipe üòä  mild gibberish\n",
      "16                           √∞≈∏Àú¬Æ√∞≈∏Àú¬Æ√∞≈∏Àú¬Æ√∞≈∏Àú¬Æ√∞≈∏Àú¬Æ√∞≈∏Àú¬Æ  mild gibberish\n",
      "19                                              ‚ù§‚ù§‚ù§‚ù§‚ù§  mild gibberish\n",
      "20                                               ‚ù§‚ù§‚ù§‚ù§  mild gibberish\n",
      "22  I still dont understand should I apply wax fir...  mild gibberish\n",
      "26  @sharshot adkari Already plenty videos on that...  mild gibberish\n",
      "27                                                 üí•üí•  mild gibberish\n",
      "28                                            TrueüòÇüòÇ‚ù§  mild gibberish\n",
      "30                                            Nice√¢¬ù¬§  mild gibberish\n",
      "35  Los videos en la ducha son los mejores√∞≈∏Àú¬ç√∞≈∏Àú‚Ä†...  mild gibberish\n",
      "37                                                √¢¬ù¬§  mild gibberish\n",
      "39  Hey hi..\\nHope you are doing good √∞≈∏≈í¬∏√∞≈∏≈í¬∏\\nIt...  mild gibberish\n",
      "40                                                ‚ù§‚ù§‚ù§  mild gibberish\n",
      "41  Your hair setting bro.ü•∫ü•∫ü•∫ü•∫ü•∫ü•∫\\nMine becomes a t...  mild gibberish\n",
      "42               Please make the video about BB cream  mild gibberish\n",
      "43                                this chat is gay af  mild gibberish\n",
      "44  The 'blonde' üò∂üíÄ...(Cough dark brown with gold ...  mild gibberish\n",
      "45                                        ReuploadedüòÇ  mild gibberish\n",
      "46                      Please make video on bb cream  mild gibberish\n",
      "48               Bro plz make a video on BB cream too  mild gibberish\n",
      "51                                     Superb content  mild gibberish\n",
      "52                                       ‚ù§ amazing ‚ù§üòä  mild gibberish\n",
      "54  I would so be playing with that constantly! Lo...  mild gibberish\n",
      "55                        üëçüèΩüëçüèΩüëçüèΩüëçüèΩ‚ù§Ô∏èüíôüíõüíõüß°so coolüëçüèΩüëçüèΩüëçüèΩ  mild gibberish\n",
      "56                                         Thankiiies  mild gibberish\n",
      "57  Thar pink and purple would completely work on ...  mild gibberish\n",
      "60                                        Love ya boo  mild gibberish\n",
      "63  Love this you should definitely do neon split ...  mild gibberish\n",
      "67                                         Trop belle  mild gibberish\n",
      "68                                           ‡¶π‡¶æ ‡¶π‡¶æ ‡¶π‡¶æ  mild gibberish\n",
      "77  Omg this is so cool!! Lol u look rad with all ...  mild gibberish\n",
      "78                                               Call  mild gibberish\n",
      "85                                      Which shade??  mild gibberish\n",
      "87  plz tell me she did a test strand before she d...  mild gibberish\n",
      "91  Nah, it's the way bro did ennie minnie mainie ...  mild gibberish\n",
      "93                         ‚Äã@Curiousertyou try this ?  mild gibberish\n",
      "94                                               üå∏üå∏üå∏üå∏  mild gibberish\n",
      "96  Omg this is the cutest ever well done and I mi...  mild gibberish\n",
      "97  i didn't like the dry down of carlisle, i have...  mild gibberish\n",
      "98      KJo should cast him opposition Ranveer Singh.  mild gibberish\n",
      "99  Always at work when you post ü§¶üèæ‚Äç‚ôÄÔ∏è going to ha...  mild gibberish\n"
     ]
    }
   ],
   "source": [
    "# Filter only rows predicted as mild gibberish\n",
    "gibberish_df = df[df[\"spam\"] == \"mild gibberish\"]\n",
    "\n",
    "print(gibberish_df[[\"textOriginal\", \"spam\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
